{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "import multiprocessing\n",
    "import time\n",
    "#import profile\n",
    "#import pstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_ranking(n):\n",
    "    ranking = {}\n",
    "    chooseList = [i for i in range(0,n)]\n",
    "    for i in range(len(chooseList)):\n",
    "        x = random.choice(chooseList)\n",
    "        ranking[i] = x\n",
    "        chooseList.remove(x)\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def violations(ranking, edgeList): ##Given a ranking, find the number of violations.\n",
    "    # edgeList is a dictionary of tuple of edge -> its weight\n",
    "    number_of_violations = 0\n",
    "    for (i,j) in edgeList:\n",
    "        if ranking[i] < ranking[j]:\n",
    "            number_of_violations+=edgeList[(i,j)]\n",
    "    return number_of_violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_edgeDict(AdjList):\n",
    "    edgeWeight_dict = {}\n",
    "    weighted_edgeList = []\n",
    "    for i in range(len(AdjList)):\n",
    "        for edge_and_weight in AdjList[i]:\n",
    "            weighted_edgeList.append((i,edge_and_weight[0],edge_and_weight[1]))\n",
    "    for i in range(len(weighted_edgeList)):\n",
    "        edgeWeight_dict[(weighted_edgeList[i][0],weighted_edgeList[i][1])] = weighted_edgeList[i][2]\n",
    "\n",
    "    return edgeWeight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_communityOrder(collapsed_AdjList): # Here G is a collapsed graph version of the original graph, and is weighted and directed.\n",
    "    n = len(collapsed_AdjList)\n",
    "    \n",
    "    between_edges = 0  # Number of edges in between communities.\n",
    "    \n",
    "    for i in range(len(collapsed_AdjList)):\n",
    "        for j in range(len(collapsed_AdjList)):\n",
    "            if i != j:\n",
    "                between_edges += collapsed_AdjList[i][j][1]\n",
    "        \n",
    "       \n",
    "        \n",
    "    ranking = random_ranking(n)\n",
    "    #print('initial ranking = ', ranking)\n",
    "    \n",
    "    edgeWeight_dict = get_weighted_edgeDict(collapsed_AdjList)\n",
    "    \n",
    "    current_number_of_violations = violations(ranking, edgeWeight_dict)\n",
    "    #print(\"initial violations = \", current_number_of_violations)\n",
    "\n",
    "    number_of_passes = 0\n",
    "    t = 0\n",
    "    time = []\n",
    "    violation = []\n",
    "    number_of_violations = -1\n",
    "    #print(\"max number of passes = \", n*(n-1)/2)\n",
    "    while number_of_passes < (5 * n): # Here, we keep the max passes as 5n and not nC2 because the number of \n",
    "        # communities in the collapsed graph would be pretty low, and so 5n is taken so as to ensure that\n",
    "        # sufficient number of checks for swaps have been done before returning the the final order.\n",
    "        \n",
    "        time.append(t)\n",
    "        t+=1\n",
    "        violation.append(current_number_of_violations)\n",
    "        \n",
    "        #Choose 2 random nodes and propose their swap.\n",
    "        nodeList = [i for i in range(n)]\n",
    "        x = random.choice(nodeList)\n",
    "        nodeList.remove(x)\n",
    "        y = random.choice(nodeList)\n",
    "        \n",
    "        #print(\"nodes chosen for swapping = \", x, y)\n",
    "        rank_X = ranking[x]\n",
    "        rank_Y = ranking[y]\n",
    "        temp = ranking[x]\n",
    "        ranking[x] = ranking[y]\n",
    "        ranking[y] = temp\n",
    "        #print('swapped ranking = ', ranking)\n",
    "        number_of_violations = violations(ranking, edgeWeight_dict)\n",
    "        #print('violations after swap = ', number_of_violations)\n",
    "        if number_of_violations > current_number_of_violations:\n",
    "            ## we do not change the ordering, so we revert back.\n",
    "            #print('revert back')\n",
    "            ranking[x] = rank_X\n",
    "            ranking[y] = rank_Y\n",
    "            number_of_passes+=1\n",
    "        elif number_of_violations == current_number_of_violations:\n",
    "            ## we keep the swapped ordering (swap is accpeted)\n",
    "            #print('is same')\n",
    "            number_of_passes+=1\n",
    "        else:\n",
    "            ## we keep the swapped ordering\n",
    "            #print('keep the swapped order')\n",
    "            number_of_passes = 0\n",
    "            current_number_of_violations = number_of_violations\n",
    "            #print(\"number of passes set to 0\")\n",
    "    #print(\"Final violations = \", current_number_of_violations)    \n",
    "    #print('number of passes = ',number_of_passes)\n",
    "    #plt.plot(time, violation) #, label = label_name)#, linestyle='dashed')\n",
    "    #plt.xlabel('Time elapsed')\n",
    "    #plt.ylabel('Number of violations')\n",
    "    #print(\"ranking before reversing = \", ranking)\n",
    "    #print(\"Then we change every value to n - value.\")\n",
    "    reversed_ranking = {}\n",
    "    for key, value in ranking.items():\n",
    "        reversed_ranking[key] = n - value - 1\n",
    "    #print(\"final ranking = \", reversed_ranking)\n",
    "\n",
    "    if between_edges == 0:\n",
    "        between_edges = 1\n",
    "    fractional_final_violation = current_number_of_violations / between_edges\n",
    "    return reversed_ranking, between_edges, fractional_final_violation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_graph(AdjList, communities, c): #G is a directed, unweighted graph\n",
    "    \n",
    "    number_of_communities = c\n",
    "    collapsed_AdjList = [[] for k in range(number_of_communities)]\n",
    "    \n",
    "    weight_between_communities = [[0 for k in range(number_of_communities)] for k in range(number_of_communities)]\n",
    "   \n",
    "    for i in range(len(AdjList)):\n",
    "        for eachnode in AdjList[i]:\n",
    "            weight_between_communities[communities[i]][communities[eachnode[0]]] += eachnode[1]\n",
    "            \n",
    "    \n",
    "    for i in range(number_of_communities):\n",
    "        for j in range(number_of_communities):\n",
    "            #if weight_between_communities[i][j] != 0:\n",
    "            collapsed_AdjList[i].append((j,weight_between_communities[i][j]))\n",
    "            \n",
    "    return collapsed_AdjList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You have to remove all networkx, so store everything in your own data structure. Even for nodes you do not call the\n",
    "# G.nodes() function, rather you save them at the beginning and never compute this n more than once. Also you don't \n",
    "# use G.add_edges() because that line is executed a lot of times. You just do not use the 'G.' anywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def B_val(G, u, v, rho, flag_model):\n",
    "    w = -1\n",
    "    if G.has_edge(u, v):\n",
    "        w = 1\n",
    "    else:\n",
    "        w = 0\n",
    "    m = G.number_of_edges()\n",
    "    \n",
    "    value = -1\n",
    "    \n",
    "    if flag_model == 0:\n",
    "        value = (w - ((G.out_degree[u] * G.in_degree[v])/(m)))/(m)\n",
    "    else:\n",
    "        value = (w - rho)/m\n",
    "    \n",
    "    #print(u, v, value)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @do_cprofile\n",
    "def get_B_matrix(AdjList, rho, flag_model, degree_in, degree_out):\n",
    "    B_matrix = []\n",
    "    number_of_nodes = len(AdjList)\n",
    "    number_of_edges = 0\n",
    "    for node in range(number_of_nodes):\n",
    "        number_of_edges += degree_out[node] \n",
    "            \n",
    "    if flag_model == 1: ## use Erdos-Renyi Null model\n",
    "        B_matrix = [[-rho for i in range(number_of_nodes)] for j in range(number_of_nodes)]\n",
    "        for i in range(number_of_nodes):\n",
    "            for eachnode in AdjList[i]:\n",
    "                B_matrix[i][eachnode[0]] += eachnode[1]\n",
    "\n",
    "                \n",
    "    elif flag_model == 0: ## use Configuration Null model\n",
    "        #print(\"before adding 1\", B_matrix)\n",
    "        for i in range(number_of_nodes):\n",
    "            B_list = []\n",
    "            for j in range(number_of_nodes):\n",
    "                #print('for node ', i, j, 'we have B value = ', -((degree_out[i]*degree_in[j])/number_of_edges))\n",
    "                B_list.append(-((degree_out[i]*degree_in[j])/number_of_edges))\n",
    "            B_matrix.append(B_list)\n",
    "                \n",
    "        for i in range(number_of_nodes):\n",
    "            for eachnode in AdjList[i]:\n",
    "                B_matrix[i][eachnode] += 1\n",
    "        #print(\"after adding 1\", B_matrix) \n",
    "                \n",
    "    for i in range(number_of_nodes):\n",
    "        for j in range(number_of_nodes):\n",
    "            B_matrix[i][j] = B_matrix[i][j]/number_of_edges\n",
    "    #print(\"before return \", B_matrix)\n",
    "    return B_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## b_{rs} = sum_over_{ij} [B_{ij}.delta_{gi,r}.delta_{gj,s}]\n",
    "## where B_{ij} = 1/m * [A_{ij} - (k-out_{i} * k-in_{j})/m]\n",
    "\n",
    "## this function performs similar to nx.networkx.algorithms.community.modularity for modularity\n",
    "\n",
    "def brs_matrix(AdjList, community, rho, flag_model, c, degree_in, degree_out):\n",
    "    # *** this function works only for unweighted and directed graphs***\n",
    "    \n",
    "    # input : AdjList of the graph\n",
    "    #       : community is a n-sized list of the community that each of the n nodes belong to, \n",
    "    #       : community index must start from 0 **\n",
    "    \n",
    "    # output : returns the b_rs matrix using the above formula\n",
    "    #t11 = time.time()\n",
    "    #print(\"brs matrix start time = \", t11)\n",
    "    number_of_communities = c\n",
    "    number_of_nodes = len(community)\n",
    "    \n",
    "    b_rs = [[0 for k in range(number_of_communities)] for i in range(number_of_communities)]\n",
    "    \n",
    "    # Now, we make a list A of lists, where list A is of size c and each of the lists store the nodes that belong to \n",
    "    # each of the c communities. Hence the r_list and the s_list will not be re-computed in every iteration like we \n",
    "    # are doing now.\n",
    "    \n",
    "    partitions = [[] for i in range(c)]\n",
    "    for k in range(len(community)):\n",
    "        partitions[community[k]].append(k)\n",
    "\n",
    "    # Get the B_matrix computed here, this function should be called only once in an entire run of the full program.\n",
    "    B_matrix = get_B_matrix(AdjList, rho, flag_model, degree_in, degree_out)\n",
    "    #print(B_matrix)\n",
    "        \n",
    "    for r in range(number_of_communities):\n",
    "        for s in range(number_of_communities):\n",
    "            r_list = partitions[r]\n",
    "            s_list = partitions[s]\n",
    "            sum_B = 0\n",
    "            for i, j in product(r_list, s_list):\n",
    "                    sum_B += B_matrix[i][j]    \n",
    "            b_rs[r][s] = sum_B\n",
    "    #t22 = time.time()\n",
    "    #print(\"brs matrix end time = \", t22)\n",
    "    #print('total time to build the brs matrix for', G.number_of_nodes(), 'nodes = ', (t22-t11)/60, 'mins.')\n",
    "    return b_rs, B_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_U(b_rs, comm_count):\n",
    "    # output : returns the summation of b_rs values across groups i.e for all b_rs with r<s\n",
    "    \n",
    "    number_of_communities = comm_count\n",
    "    \n",
    "    sum_u = 0\n",
    "    for r in range(number_of_communities-1):\n",
    "        for s in range(r+1,number_of_communities):\n",
    "            sum_u += b_rs[r][s]\n",
    "            \n",
    "    return sum_u        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_D(b_rs, comm_count):\n",
    "    # output : returns the summation of b_rs values within groups i.e for all b_rs with r=s.\n",
    "\n",
    "    number_of_communities = comm_count\n",
    "    sum_d = 0\n",
    "    for r in range(number_of_communities):\n",
    "            sum_d += b_rs[r][r]\n",
    "            \n",
    "    return sum_d   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_in_U(number_of_nodes, i, old_comm, new_comm, community, B_matrix):\n",
    "    '''\n",
    "    U is basically the sum of the upper triangle of the b_rs matrix.\n",
    "    \n",
    "    if new_comm(i) > old_comm(i), then.........\n",
    "    there is no affect in overall U for the edges entering i from the nodes belonging to community less than \n",
    "    old_comm(i), because they were already counted before and they should be counted now too. For edges coming from \n",
    "    community >= old_comm(i) and less than new_comm(i) to i, all the *B values* will now get added to the overall U,\n",
    "    because these were not counted in overall U previously. There is no affect for edges coming from community\n",
    "    >= new_comm(i) to node i in the overall U value, because they were anyway not counted previously and should not \n",
    "    be counted now too.\n",
    "    The edges going from i to all the community <=old_comm(i) were not counted in overall U previously and should \n",
    "    not be counted now too. The edges going from i to all the community > old_comm(i) and <= new_comm(i) were\n",
    "    counted previously, but should not be counted now. So all those *B values* should now be subtracted from overall\n",
    "    U. The edges going from i to all the community greater than new_comm(i) should not have any affect in overall U\n",
    "    because they were already counted before and they should be counted now too.\n",
    "    \n",
    "    \n",
    "    if new_comm(i) < old_comm(i), then.........\n",
    "    there is no affect in overall U for the edges entering i from the nodes belonging to community less than \n",
    "    new_comm(i), because they were already counted before and they should be counted now too. For edges coming from \n",
    "    community >= new_comm(i) and less than old_comm(i) to i, all the *B values* now needs to be subtracted from the\n",
    "    overall U, because these were counted in overall U previously, but should not be counted now. There is no affect \n",
    "    for edges coming from community >= old_comm(i) to node i in the overall U value, because they were anyway \n",
    "    not counted previously and should not be counted now too.\n",
    "    The edges going from i to all the community <=new_comm(i) were not counted in overall U previously and should \n",
    "    not be counted now too. The edges going from i to all the community > new_comm(i) and <= old_comm(i) were not\n",
    "    counted previously, but should added to overall U now. So all those *B values* should be added to the overall\n",
    "    U. The edges going from i to all the community greater than old_comm(i) should not have any affect in overall U\n",
    "    because they were already counted before and they should be counted now too.\n",
    "    \n",
    "    Here we just record the change, i.e the delta value.\n",
    "    '''\n",
    "    delta = 0\n",
    "    \n",
    "    if new_comm > old_comm:\n",
    "        #print('we have new_comm > old_comm')\n",
    "        #print('checking each node from the list - ', list(G.nodes()))\n",
    "        for node in range(number_of_nodes):\n",
    "            if node != i:\n",
    "                #print('neighbour = ',node)\n",
    "                if community[node] >= old_comm and community[node] < new_comm:\n",
    "                    #print('we will add the B value for this neighbour')\n",
    "                    delta = delta + B_matrix[node][i]\n",
    "        #print('checking each node from the list - ', list(G.nodes())) \n",
    "        for node in range(number_of_nodes):\n",
    "            if node!=i:\n",
    "                #print('neighbour = ',node)\n",
    "                if community[node] > old_comm and community[node] <= new_comm:\n",
    "                    #print('we will subtract the B value for this neighbour')\n",
    "                    delta = delta - B_matrix[i][node]\n",
    "                \n",
    "    elif new_comm < old_comm:\n",
    "        #print('we have new_comm < old_comm')\n",
    "        #print('checking each node from the list - ', list(G.nodes()))\n",
    "        for node in range(number_of_nodes):\n",
    "            if node != i:\n",
    "                #print('neighbour = ',node)\n",
    "                if community[node] >= new_comm and community[node] < old_comm:\n",
    "                    #print('we will subtract the B value for this neighbour')\n",
    "                    delta = delta - B_matrix[node][i]\n",
    "                \n",
    "        #print('checking each node from the list - ', list(G.nodes()))    \n",
    "        for node in range(number_of_nodes):\n",
    "            if node != i:\n",
    "                #print('neighbour = ',node)\n",
    "                if community[node] > new_comm and community[node] <= old_comm:\n",
    "                    #print('we will add the B value for this neighbour')\n",
    "                    delta = delta + B_matrix[i][node]\n",
    "    #print(delta)            \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_in_D(number_of_nodes, i, old_comm, new_comm, community, B_matrix):\n",
    "    '''\n",
    "    From the overall D, we can subtract the values which results from i leaving its old community and add the\n",
    "    values which result from i joining its new community.\n",
    "    \n",
    "    We subtract all the *B values* for the edges going from i to all the nodes of community old_comm(i) and the edges\n",
    "    entering i from the nodes of community old_comm(i), and we add all the *B values* for the edges going from i to \n",
    "    all the nodes of community new_comm(i) and the edges entering i from the nodes of community new_comm(i).\n",
    "    '''\n",
    "    delta = 0\n",
    "    \n",
    "    for node in range(number_of_nodes):\n",
    "        if node!=i:\n",
    "            if community[node] == old_comm:\n",
    "                delta = delta - B_matrix[node][i]\n",
    "            elif community[node] == new_comm:\n",
    "                delta = delta + B_matrix[node][i]\n",
    "            \n",
    "    for node in range(number_of_nodes):\n",
    "        if node!=i:\n",
    "            if community[node] == old_comm:\n",
    "                delta = delta - B_matrix[i][node]\n",
    "            elif community[node] == new_comm:\n",
    "                delta = delta + B_matrix[i][node]\n",
    "            \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_in_R(number_of_nodes, i, old_comm, new_comm, community, alpha, B_matrix):\n",
    "    delta_U = change_in_U(number_of_nodes, i, old_comm, new_comm, community, B_matrix)\n",
    "    \n",
    "    delta_D = change_in_D(number_of_nodes, i, old_comm, new_comm, community, B_matrix)\n",
    "    \n",
    "    delta_R = (alpha*delta_U) + ((1 - alpha)*delta_D)\n",
    "    \n",
    "    #print('delta_R = ', delta_R)\n",
    "    return delta_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rankularity(community, b_rs, alpha):\n",
    "    # output : returns the R value of a given partition\n",
    "    number_of_communities = len(set(community))\n",
    "    U = calculate_U(b_rs, number_of_communities)\n",
    "    D = calculate_D(b_rs, number_of_communities)\n",
    "    \n",
    "    R = (alpha*U) + ((1 - alpha)*D)\n",
    "    \n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying Aaron's code for locally greedy heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeAMove(number_of_nodes, community, fr, alpha, c, old_R, B_matrix):\n",
    "    # For each non 'frozen' node in the current partition, this function tries all (c-1) possible group moves for it\n",
    "    # It returns the combination of [node i and new group r] that produces the best log-likelihood over the non-frozen set.\n",
    "    \n",
    "    # input  : AdjList of the input graph\n",
    "    #        : community is a list showing the partition of G's nodes with a community label at each index.\n",
    "    #        : fr is an n-sized binary list of frozen nodes, where 0 = not frozen and 1 = frozen.\n",
    "    #        : alpha is a constant used in the Rankularity calculation\n",
    "    #        : rho is used if the Null is the ER Model\n",
    "    #        : flag_model = 0 for CM and 1 for ER\n",
    "    \n",
    "    # output : bestR, the best Rankularity found\n",
    "    #        : bestMove, [i,r] the node i and new group r to achieve bestL\n",
    "    \n",
    "    #b_rs = brs_matrix(G, community, rho, flag_model)\n",
    "    \n",
    "    best_R    = -np.inf\n",
    "    # ***** bestR SHOULD be made to -infinity because makeAMove HAS to for sure suggest for \n",
    "    # the best move out of all the (n-t)(c-1) possible single-node moves, for t nodes frozen (moved) so far. \n",
    "    \n",
    "    bestMove = [-1, -1] # [node i, group r] assignment for bestR\n",
    "\n",
    "    # c is the number of communities.\n",
    "    \n",
    "    for i in range(number_of_nodes):\n",
    "        if fr[i] == 0:   # if i is not a 'frozen' node\n",
    "            s = community[i]    #  the current community label of i\n",
    "            for r in range(c): #  try all the groups\n",
    "                \n",
    "                if r != s:     #    except the current one\n",
    "                    community[i] = r   #    move i to group r\n",
    "                    \n",
    "                    current_R = old_R + change_in_R(number_of_nodes, i, s, r, community, alpha, B_matrix)\n",
    "                    #print(\"current_R in MAKE = \", current_R)\n",
    "                    # calculate change in R for this new partition\n",
    "                    current_R = round(current_R, 10)\n",
    "                    best_R = round(best_R, 10)\n",
    "                    # print(f'v[{i}] g[{int(s)}] --> g[{r}] : {thisR}')\n",
    "                    if current_R - best_R > 0.001:     # \n",
    "                        best_R    = current_R  #  best Rankularity so far\n",
    "                        bestMove = [i,r]  #  the move that gets us there\n",
    "                        #print('best_R in MAKE is updated to ', best_R)\n",
    "            community[i]= s   # put i back where we found it\n",
    "                ##### do not modify below here #####  \n",
    "                \n",
    "    #print(\"Best to move node\",bestMove[0],\"from community\", community[bestMove[0]], \"to community\",bestMove[1])\n",
    "    #print('..which will make the R', bestR)\n",
    "    return best_R,bestMove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem is in makeaMove, at the end all becomes 0,\n",
    "## so size of set of community list becomes 1, so best_R stays at minus infinity, minus infinity is returned, and \n",
    "## bestMove has -1 community in it, current Rankularity =  -inf untill the next round phase is started, but then\n",
    "## again the same thing happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_z(n,c):\n",
    "    # input  : number of nodes n, and number of groups c\n",
    "    # output : returns a random partition z (n x 1), in which z_i = Uniform(0,c-1)\n",
    "\n",
    "    import random as rnd\n",
    "    rnd.seed()\n",
    "    \n",
    "    z = [1 for i in range(n)]\n",
    "    '''for i in range(10):\n",
    "        z[i] = 0'''\n",
    "        \n",
    "\n",
    "    ##### do not modify above here #####\n",
    "    ### YOUR CODE\n",
    "    for i in range(n):\n",
    "        z[i] = int(rnd.randint(0,c-1))\n",
    "\n",
    "    ##### do not modify below here #####\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_greedy_heuristic(AdjList, alpha_value, number_of_communities, rho, flag_model, degree_in, degree_out):\n",
    "    T = 30\n",
    "    n = len(AdjList)\n",
    "    c = number_of_communities\n",
    "    alpha = alpha_value\n",
    "    \n",
    "    \n",
    "    community  = random_z(n,c) #[0,1,2,0,1,2,1,2,2,0,1]   # initial partition\n",
    "    \n",
    "    Rankularity_values = []                # Rankularity over the entire algorithm (via .append)\n",
    "\n",
    "    current_partition = community        # partition to start with.\n",
    "    #print(\"randomised starting partition = \", current_partition)\n",
    "    b_rs, B_matrix = brs_matrix(AdjList, community, rho, flag_model, c, degree_in, degree_out)  # b_rs matrix to start with\n",
    "    #print(b_rs)\n",
    "    best_R = calculate_rankularity(current_partition, b_rs, alpha)  # initial Rankularity score\n",
    "    #print(\"starting rankularity for randomised partition = \", best_R)\n",
    "    #print('starting bestR = ', bestR)\n",
    "    #Rankularity_values.append(best_R)            # track Rankularity\n",
    "\n",
    "    # 3.0 the main loop setup\n",
    "    #print(f'phase[0] initial z, R = {bestR}')\n",
    "                \n",
    "    #drawGz(G,current_partition)\n",
    "\n",
    "    best_partition = community\n",
    "\n",
    "    t  = 1  # counter for number of partitions considered, in this phase\n",
    "    pc = 0  # counter for number of phases completed\n",
    "\n",
    "    while True:\n",
    "        # 3.1 visualization of this phase's initial partition\n",
    "        #print('Phase no. = ',pc,\"best_R =\", bestR)\n",
    "        #drawGz(G,current_partition)\n",
    "        #b_rs = brs_matrix(G, current_partition, rho, flag_model)  # b_rs matrix to start with\n",
    "        #current_R = calculate_rankularity(current_partition, b_rs, alpha)  # initial Rankularity score\n",
    "        #current_R = best_R\n",
    "        f = [0 for i in range(n)]  # no nodes frozen\n",
    "        flag_updated = 0   # flag becomes 1 if we find at least one new move in the entire phase that increases our R.\n",
    "        #print(\"\\n \\n new phase begun with best_R = \", best_R, \"and partition \", current_partition)\n",
    "        # loop over all the nodes in G, making greedy move for each\n",
    "        #b_rs = brs_matrix(G, best_partition, rho, flag_model)  # b_rs matrix to start with\n",
    "        #print(b_rs)\n",
    "        #print(\"taken best_R = \", best_R)\n",
    "        #best_R = calculate_rankularity(best_partition, b_rs, alpha)\n",
    "        #print(\"after best_R = \", best_R)\n",
    "        current_partition = copy.deepcopy(best_partition)\n",
    "        ############\n",
    "        current_R = best_R\n",
    "        t = 0\n",
    "        ############\n",
    "        for j in range(n):\n",
    "            \n",
    "            #print(f'phase[{pc}] step {j}')\n",
    "            #print('partition that goes into makeAMove function -', current_partition)\n",
    "            #print(\"makeAMove sent with partiton \", current_partition, \"and current Rankularity = \", current_R)\n",
    "            #time11 = time.time()\n",
    "            choice_R,choiceMove = makeAMove(n, current_partition, f, alpha, c, current_R, B_matrix)\n",
    "            #print(\"choice_R returned by makeAMove = \", choice_R)\n",
    "            choice_R = round(choice_R,10)\n",
    "            best_R = round(best_R,10)\n",
    "            i = choiceMove[0]    # move node i\n",
    "            r = choiceMove[1]    # to community r\n",
    "            f[i]    = 1          # freeze node i, so frozen list f is updated here \n",
    "            current_partition[i] = r          # make the greedy choice\n",
    "            current_R = choice_R\n",
    "            #print(\"current_changed partition = \", current_partition)\n",
    "\n",
    "            # Remember, freezing a node and updating its community is mandatory in every iteration.\n",
    "            Rankularity_values.append(current_R) # track Rankularity (even if it decreases)\n",
    "            if choice_R - best_R > 0.00000001:  # track best R and partition in the phase\n",
    "                #print(choice_R, best_R, choiceMove)\n",
    "                best_R = choice_R  # update the best Rankularity we have yet (among all phases)\n",
    "                best_partition = copy.deepcopy(current_partition)  #\n",
    "                #print(\"best_R in localGreedy updated to \", best_R, \"with best partition as \", best_partition)\n",
    "                #print(\"\\n\\n\\n YAYY \\n\\n\")\n",
    "                flag_updated = 1\n",
    "                #print('new choiceR = ', choiceR)\n",
    "                #print(\"bestR is updated to\", bestR)\n",
    "                #print(\"best Community is updated to\", best_partition)\n",
    "\n",
    "            t  = t  + 1          # increment step counter\n",
    "            #time22 = time.time()\n",
    "            #print('t = ',t, \"took \", (time22-time11)/60, \"mins.\")\n",
    "            #print(t)\n",
    "            #if t%5 == 0:\n",
    "                #print(\"step counter inside a phase (out of 200 steps) = \", t)\n",
    "            \n",
    "            \n",
    "        # End end of each phase, check convergence criteria; if not converged, setup for next phase\n",
    "        if flag_updated==0:\n",
    "            # HALT: no better partition was found for this phase\n",
    "            #print(f' --> WE HAVE CONVERGENCE due to no updation <-- ')\n",
    "            break\n",
    "        elif pc>=T:\n",
    "            # HALT: we've run out of phases\n",
    "            #print(f' --> WE HAVE CONVERGENCE due to running out of phase<-- ')\n",
    "            break\n",
    "        else:\n",
    "            pc = pc + 1          # increment phase counter\n",
    "            #print(\"pc = \", pc)\n",
    "            \n",
    "\n",
    "            \n",
    "    #print(f'phase[{pc}], final_R =', bestR)\n",
    "    #drawGz(G,best_partition)\n",
    "    #print(\"Final best partiton = \", best_partition)\n",
    "    #plotLL(Rankularity_values,pc)\n",
    "    #print(\"final pc = \", pc)\n",
    "    #print(best_partition)\n",
    "    #drawGz(G,best_partition)\n",
    "    return best_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#needs to be fixed, probably the problem is not because of ER, rather the code is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Algo is working more or less correctly, plant a partition and check now. DONE - CORRECT!!\n",
    "# Next, repeat the experiements done in paper with the fraction of correct nodes.\n",
    "\n",
    "# Do further analysis on how the value of alpha (IMP), the number of community, \n",
    "# the value of noise p and other factors can affect the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## So in order to know how Rankularity algo is performing, \n",
    "## it might be insightful to check the NMI between the ground truth and the algo's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now that Rankularity algo is working, NEXT STEP - \n",
    "## We construct networks in which the probability of each edge is chosen according \n",
    "## to the planted community structure of SBM with probability p and according to the \n",
    "## structurelessness with probability (1 − p), and then measure the accuracy of label \n",
    "## recovery as p is varied from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First write a function to calculate fraction of correct nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fraction_of_correct_nodes(ground_truth, actual):\n",
    "    correct = 0\n",
    "    for i in range(len(ground_truth)):\n",
    "        if ground_truth[i] == actual[i]: # if this node's order was correctly identified\n",
    "            correct+=1\n",
    "            \n",
    "    fraction = correct/len(ground_truth)\n",
    "    \n",
    "    #nmi = sklearn.metrics.normalized_mutual_info_score(ground_truth, actual)\n",
    "\n",
    "    '''if fraction > (1 - fraction):\n",
    "        print(\"correct fraction = \", fraction)\n",
    "        return fraction\n",
    "    else:\n",
    "        print(\"correct fraction = \",1 - fraction)\n",
    "        return 1-fraction'''\n",
    "    \n",
    "    print('fraction correct = ', fraction)\n",
    "    return fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawGz(G,z):\n",
    "    # DO NOT MODIFY THIS FUNCTION\n",
    "    # This function draws G with node labels from partition z\n",
    "    #\n",
    "    # input  : G is a networkx graph\n",
    "    #        : z is a dictionary of group labels for G's nodes\n",
    "    # output : none\n",
    "    # \n",
    "    # WARNING: function is optimistic: assumes inputs are properly formatted\n",
    "\n",
    "    plt.figure(figsize = (20,15))\n",
    "    colors = ['#d61111','#11c6d6','#d67711','#11d646','#1b11d6','#d611cc'] # map node labels to colors (for the visualization)\n",
    "\n",
    "    node_colors = []\n",
    "    for i in G.nodes():\n",
    "        node_colors.append(colors[int(z[int(i)-1])])\n",
    "    nsize  = 700\n",
    "    flabel = True\n",
    "\n",
    "    if G.order() > 50:\n",
    "        nsize  = 800\n",
    "        flabel = True\n",
    "        \n",
    "    nx.draw_networkx(G, pos=nx.spring_layout(G), arrows=True, with_labels=flabel,node_size=nsize,width=2,node_color=node_colors, alpha = 1) # draw it pretty\n",
    "    limits=plt.axis('off')                                      # turn off axes\n",
    "    plt.show() \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "def community_layout(g, partition):\n",
    "    \"\"\"\n",
    "    Compute the layout for a modular graph.\n",
    "\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    g -- networkx.Graph or networkx.DiGraph instance\n",
    "        graph to plot\n",
    "\n",
    "    partition -- dict mapping int node -> int community\n",
    "        graph partitions\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pos -- dict mapping int node -> (float x, float y)\n",
    "        node positions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    pos_communities = _position_communities(g, partition, scale=3.)\n",
    "\n",
    "    pos_nodes = _position_nodes(g, partition, scale=1.)\n",
    "\n",
    "    # combine positions\n",
    "    pos = dict()\n",
    "    for node in g.nodes():\n",
    "        pos[node] = pos_communities[node] + 2.5*pos_nodes[node]\n",
    "\n",
    "    return pos\n",
    "\n",
    "def _position_communities(g, partition, **kwargs):\n",
    "\n",
    "    # create a weighted graph, in which each node corresponds to a community,\n",
    "    # and each edge weight to the number of edges between communities\n",
    "    between_community_edges = _find_between_community_edges(g, partition)\n",
    "\n",
    "    communities = set(partition.values())\n",
    "    hypergraph = nx.DiGraph()\n",
    "    hypergraph.add_nodes_from(communities)\n",
    "    for (ci, cj), edges in between_community_edges.items():\n",
    "        hypergraph.add_edge(ci, cj, weight=len(edges))\n",
    "\n",
    "    # find layout for communities\n",
    "    pos_communities = nx.spring_layout(hypergraph, **kwargs)\n",
    "\n",
    "    # set node positions to position of community\n",
    "    pos = dict()\n",
    "    for node, community in partition.items():\n",
    "        pos[node] = pos_communities[community]\n",
    "\n",
    "    return pos\n",
    "\n",
    "def _find_between_community_edges(g, partition):\n",
    "\n",
    "    edges = dict()\n",
    "\n",
    "    for (ni, nj) in g.edges():\n",
    "        ci = partition[ni]\n",
    "        cj = partition[nj]\n",
    "\n",
    "        if ci != cj:\n",
    "            try:\n",
    "                edges[(ci, cj)] += [(ni, nj)]\n",
    "            except KeyError:\n",
    "                edges[(ci, cj)] = [(ni, nj)]\n",
    "\n",
    "    return edges\n",
    "\n",
    "def _position_nodes(g, partition, **kwargs):\n",
    "    \"\"\"\n",
    "    Positions nodes within communities.\n",
    "    \"\"\"\n",
    "\n",
    "    communities = dict()\n",
    "    for node, community in partition.items():\n",
    "        try:\n",
    "            communities[community] += [node]\n",
    "        except KeyError:\n",
    "            communities[community] = [node]\n",
    "\n",
    "    pos = dict()\n",
    "    for ci, nodes in communities.items():\n",
    "        subgraph = g.subgraph(nodes)\n",
    "        pos_subgraph = nx.kamada_kawai_layout(subgraph, **kwargs)\n",
    "        pos.update(pos_subgraph)\n",
    "\n",
    "    return pos\n",
    "\n",
    "def draw_trial(g, z):\n",
    "    # to install networkx 2.0 compatible version of python-louvain use:\n",
    "    # pip install -U git+https://github.com/taynaud/python-louvain.git@networkx2\n",
    "    from community import community_louvain\n",
    "\n",
    "    partition = {}\n",
    "    for i in range(len(z)):\n",
    "        partition[i] = z[i]\n",
    "    pos = community_layout(g, partition)\n",
    "\n",
    "    plt.figure(figsize = (20,15))\n",
    "    colors = ['#d61111','#11c6d6','#d67711','#11d646','#1b11d6','#d611cc'] # map node labels to colors (for the visualization)\n",
    "\n",
    "    node_colors = []\n",
    "    for i in g.nodes():\n",
    "        node_colors.append(colors[int(z[int(i)])])\n",
    "        \n",
    "    edge_colours = [i for i in range(g.number_of_edges())]\n",
    "    nx.draw_networkx_nodes(g, pos, node_size=700,node_color=node_colors, alpha = 1)\n",
    "    nx.draw_networkx_labels(g, pos)\n",
    "    nx.draw_networkx_edges(g, pos, arrows=True, arrowsize = 20, width=2,alpha = 0.5)\n",
    "\n",
    "    #nx.draw(g, pos, node_color=list(partition.values()), with_labels=True)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def run_Rankularity(realWorldNetwork, alpha_value, number_of_communities, flag_model, return_dict):\n",
    "    # Now create a network in which the probability of each edge is chosen according \n",
    "    ## to the planted community structure of SBM with probability p and according to the \n",
    "    ## structurelessness with probability (1 − p), and then measure the accuracy of label \n",
    "    ## recovery as p is varied from 0 to 1.\n",
    "    initial_time = time.time()\n",
    "    ## ****Below is the implementation for cases with only 2 community, would generalise later.\n",
    "#     alpha = alpha_value\n",
    "#     number_of_communities = c\n",
    "#     ground_truth = []\n",
    "#     for num in range(len(list_of_numberOfNodes)):\n",
    "#         for x in range(list_of_numberOfNodes[num]):\n",
    "#             ground_truth.append(num)\n",
    "    \n",
    "    def generate_graph(realWorldNetwork):\n",
    "        # Read the real world network, nx.Graph object expected here.\n",
    "        G = realWorldNetwork\n",
    "        \n",
    "        # Create the graph\n",
    "        '''\n",
    "        To store the graph, we will maintain a list of sets (we will use sets because search operation in sets are\n",
    "        O(1)). This list will be of the size of total number of nodes nodes in graph and the sets at each index \n",
    "        will contain the set of neighbours of each node.\n",
    "        '''\n",
    "        total_number_of_nodes = G.number_of_nodes()\n",
    "        AdjList = [set() for k in range(total_number_of_nodes)]\n",
    "        degree_out = [0 for i in range(total_number_of_nodes)]\n",
    "        degree_in = [0 for i in range(total_number_of_nodes)]\n",
    "        \n",
    "        for eachedge in G.edges():\n",
    "            n1 = int(eachedge[0])\n",
    "            n2 = int(eachedge[1])\n",
    "            w = float(G.get_edge_data(eachedge[0],eachedge[1])['weight'])\n",
    "            AdjList[n1].add((n2,w))\n",
    "            degree_out[n1]+=w\n",
    "            degree_in[n2]+=w\n",
    "        \n",
    "        \n",
    "        potential_totalEdges = (total_number_of_nodes**2) - total_number_of_nodes\n",
    "        sum_of_all_edgeWeights = 0\n",
    "        for eachedge in G.edges():\n",
    "            w = float(G.get_edge_data(eachedge[0],eachedge[1])['weight'])\n",
    "            sum_of_all_edgeWeights += w\n",
    "        \n",
    "#         print(\"sum of all edgeweights = \", sum_of_all_edgeWeights)\n",
    "#         check = 0\n",
    "#         for node in range(len(AdjList)):\n",
    "#             check += degree_out[node] \n",
    "#         print(\"check using deg_out and adjlist = \", check)\n",
    "\n",
    "        rho = sum_of_all_edgeWeights/potential_totalEdges\n",
    "#         print(\"Network density = \", rho)\n",
    "#         for i in range(len(AdjList)):\n",
    "#             print(i+1, \"- \", end = \" \")\n",
    "#             if len(list((AdjList[i]))) == 0:\n",
    "#                 print(\"{}\")\n",
    "#                 continue\n",
    "#             print(\"{\", end='')\n",
    "#             for eachnode in AdjList[i]:\n",
    "#                 print(eachnode+1, end = \", \")\n",
    "#             print(\"\\b\",end=\"\")\n",
    "#             print(\"\\b\",end=\"\")\n",
    "#             print(\"}\")\n",
    "        \n",
    "        return AdjList, rho, degree_in, degree_out\n",
    "                    \n",
    "    # G = nx.stochastic_block_model(sizes, probs, seed=0, directed=True)\n",
    "    \n",
    "    alpha_values = []\n",
    "    alpha = 0\n",
    "    while alpha <= 1:\n",
    "        alpha_values.append(alpha)\n",
    "        alpha = alpha + 0.05\n",
    "        alpha = round(alpha,2)\n",
    "        \n",
    "    \n",
    "    fractional_violations = [0 for i in range(21)]\n",
    "    total_between_edges = [0 for i in range(21)]\n",
    "    run = 0\n",
    "    while run < 100:\n",
    "        if run%10 == 0:\n",
    "            print(\"run = \", run)\n",
    "        pos = 0\n",
    "        alpha = 0\n",
    "        AdjList, rho, degree_in, degree_out = generate_graph(realWorldNetwork)\n",
    "        while alpha <= 1:\n",
    "            #if run%1 == 0:\n",
    "                #print(\"alpha = \", alpha)\n",
    "\n",
    "            time1 = time.time()\n",
    "\n",
    "\n",
    "            best_partition = local_greedy_heuristic(AdjList, alpha, number_of_communities, rho, flag_model, degree_in, degree_out)\n",
    "\n",
    "\n",
    "            # Now using MVR -----\n",
    "            collapsed_Graph = collapse_graph(AdjList, best_partition, number_of_communities)\n",
    "            finalOrder, between_edges, fractional_final_violation = find_communityOrder(collapsed_Graph)\n",
    "            #if run%10 == 0:\n",
    "                #print(\"final order = \", finalOrder)\n",
    "            total_between_edges[pos] += between_edges\n",
    "            #print(\"between_edges = \", between_edges)\n",
    "            #print(\"between_edges List = \", total_between_edges)\n",
    "            fractional_violations[pos] += fractional_final_violation\n",
    "            changed_ranks = []\n",
    "            for i in range(number_of_communities):\n",
    "                changed_ranks.append(finalOrder[i])\n",
    "            final_answer = []\n",
    "            for community in best_partition:\n",
    "                final_answer.append(changed_ranks[community])\n",
    "            node_count = defaultdict(int)\n",
    "            for i in range(len(final_answer)):\n",
    "                node_count[final_answer[i]] += 1\n",
    "            if run == 0 and (alpha*10)%1 == 0:\n",
    "                print(\"alpha = \", alpha)\n",
    "                print(\"Collapsed Network = \", collapsed_Graph)\n",
    "                print(\"Community order = \", finalOrder)\n",
    "                print(\"Node counts = \", node_count)\n",
    "                \n",
    "                \n",
    "            if (run == 0 and alpha == 0.4) or (run == 0 and alpha == 0.5) or (run == 0 and alpha == 0.6) or (run == 0 and alpha == 0.8):\n",
    "                inside_list = []\n",
    "                inside_list.append(alpha)\n",
    "                for c in range(number_of_communities):\n",
    "                    group_of_nodes = []\n",
    "                    for i in range(len(final_answer)):\n",
    "                        if final_answer[i] == c:\n",
    "                            group_of_nodes.append(i)\n",
    "                    inside_list.append(group_of_nodes)\n",
    "                node_division.append(inside_list)\n",
    "                \n",
    "                \n",
    "            pos += 1  \n",
    "            #print(i, final_violations)\n",
    "            time2 = time.time()\n",
    "            \n",
    "            alpha = alpha + 0.2\n",
    "            alpha = round(alpha, 1)\n",
    "        \n",
    "        #print(\"final vio = \", final_violations)\n",
    "        #print(\"fractional vio = \", fractional_violations)\n",
    "        run+=1\n",
    "     \n",
    "    for i in range(len(total_between_edges)):\n",
    "        total_between_edges[i] = total_between_edges[i]/1\n",
    "        fractional_violations[i] = fractional_violations[i]/1\n",
    "        directionalities[i] = directionalities[i]/1\n",
    "        \n",
    "    final_time = time.time()\n",
    "    print(\"Total time taken =\", (final_time - initial_time)/3600, \"hours.\")\n",
    "    #print(\"After conversion\")\n",
    "    #print(\"final vio = \", final_violations)\n",
    "    #print(\"fractional vio = \", fractional_violations)\n",
    "    \n",
    "    plt.figure(figsize = (15,6))\n",
    "    plt.xticks(fontsize = 15 , color = 'black')\n",
    "    plt.yticks(fontsize = 15 , color = 'black')\n",
    "    plt.plot(alpha_values, total_between_edges, 'ro-', markersize = 3)\n",
    "    plt.xlabel(\"Off diagonal factor, alpha\" , fontsize = 15, color = 'black')\n",
    "    plt.ylabel(\"Number of edges between communities\" , fontsize = 15, color = 'black')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize = (15,7))\n",
    "    plt.xticks(fontsize = 15 , color = 'black')\n",
    "    plt.yticks(fontsize = 15 , color = 'black')\n",
    "    plt.plot(alpha_values, fractional_violations, 'ro-' , markersize = 3)\n",
    "    plt.xlabel(\"Off diagonal factor, alpha\" , fontsize = 15 , color = 'black')\n",
    "    plt.ylabel(\"Fraction of violations between communities\" , fontsize = 15 , color = 'black')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize = (15,7))\n",
    "    plt.xticks(fontsize = 15 , color = 'black')\n",
    "    plt.yticks(fontsize = 15 , color = 'black')\n",
    "    plt.plot(alpha_values, directionalities, 'ro-' , markersize = 3)\n",
    "    plt.xlabel(\"Off diagonal factor, alpha\" , fontsize = 15 , color = 'black')\n",
    "    plt.ylabel(\"Directionality (#downEdges/#upEdges)\" , fontsize = 15 , color = 'black')\n",
    "    plt.show()\n",
    "    \n",
    "    return node_division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_call(realWorldNetwork, number_of_communities):    \n",
    "    node_division = run_Rankularity(realWorldNetwork,number_of_communities,1)\n",
    "    return node_division\n",
    "\n",
    "def convert_graph(G):\n",
    "    print(\"number of nodes = \", G.number_of_nodes())\n",
    "    print(\"number of edges = \", G.number_of_edges())\n",
    "    converted_G = nx.DiGraph()\n",
    "        \n",
    "        \n",
    "    hash_map = {} # A dictionary where key = node label in the original network G and value = the corresponding node number between 0 and n-1\n",
    "    reverse_hash_map = {} # A dictionary where key = node number between 0 and n-1 and value = the corresponding node label in the original network G    \n",
    "    \n",
    "    nodelist = set()\n",
    "    for eachedge in list(G.edges()):\n",
    "        nodelist.add(eachedge[0])\n",
    "        nodelist.add(eachedge[1])\n",
    "    \n",
    "    i = 0\n",
    "    #print(\"number of nodes now = \", len(nodelist))\n",
    "    for node in nodelist:\n",
    "        hash_map[node] = i\n",
    "        reverse_hash_map[i] = node\n",
    "        converted_G.add_node(i)\n",
    "        i+=1\n",
    "\n",
    "    # Add edges to the new graph\n",
    "    for eachedge in list(G.edges()):\n",
    "        converted_G.add_edge(hash_map[eachedge[0]], hash_map[eachedge[1]])\n",
    "\n",
    "    return converted_G, hash_map, reverse_hash_map\n",
    "\n",
    "def get_Rankularity_results(realWorldNetwork, number_of_communities):\n",
    "    graph_and_hashes = convert_graph(realWorldNetwork)\n",
    "    converted_network = graph_and_hashes[0]\n",
    "\n",
    "    node_division = final_call(converted_network, number_of_communities) ## Averaged over 50 iterations\n",
    "    \n",
    "    return graph_and_hashes,node_division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
